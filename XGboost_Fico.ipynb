{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importation/Basinc Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import panads \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downlaod data\n",
    "\n",
    "#!wget -N https://github.com/fiddler-labs/p2p-lending-data/raw/refs/heads/master/raw_data/accepted_2007_to_2018Q3.csv.gz\n",
    "\n",
    "# If wget doesn't work use the code below\n",
    "\n",
    "import requests\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://github.com/fiddler-labs/p2p-lending-data/raw/refs/heads/master/raw_data/accepted_2007_to_2018Q3.csv.gz\"\n",
    "\n",
    "# Local file path to save the downloaded file\n",
    "file_path = \"accepted_2007_to_2018Q3.csv.gz\"\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(file_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "    print(f\"File downloaded successfully and saved as {file_path}\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DF\n",
    "df = pd.read_csv('accepted_2007_to_2018Q3.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Columns \n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Loan Status\n",
    "df.groupby(['loan_status']).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan Status to Charged Off/Fully Paid then Group by Size\n",
    "df = df[df['loan_status'].isin(['Charged Off', 'Fully Paid'])]\n",
    "df.groupby(['loan_status']).size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning on Subset of DF\n",
    "- Reduce dataset to 200k rows or less\n",
    "- Split your data for train/test\n",
    "- Build at least two models with loan_status as the target\n",
    "- Report on the models performance\n",
    "- Report on the models drivers (feature importance / effect)\n",
    "\n",
    "Plant 2 flaws in this notebook.  Do not \"give away\" the answers here.  This notebook should appear, at first glance, to create a viable model.\n",
    "\n",
    "Make a note of your flaws and be prepared to talk about how the code / results look when they are \"fixed\".  You will need to talk about those in the final presentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything else \n",
    "\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('ticks')\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are over a million rows in the dataset. For processing purposes, we are going to work on a random sample of this large dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = df.sample(frac=.05, random_state=0)\n",
    "\n",
    "print('Total Number of Rows:', '{:,}'.format(loan_df.shape[0]))\n",
    "print('Total Number of Columns:', '{:,}'.format(loan_df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values: Visualization and Feature Selection checking for and cleaning missing data. A visual check at the data set shows there are several columns with a large number of null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_values_table(df):\n",
    "    #Number of null values by column\n",
    "    missing_values_df = pd.DataFrame(df.isnull().sum(),columns=['Missing_Count'])\n",
    "    \n",
    "    #Portion of null values by column\n",
    "    missing_values_df['Portion_Missing'] = missing_values_df['Missing_Count']/df.shape[0]\n",
    "\n",
    "    #Sort by Missing_Count\n",
    "    missing_values_df = missing_values_df.sort_values(by='Missing_Count',ascending=False)  \n",
    "    \n",
    "    return missing_values_df\n",
    "\n",
    "missing_values_df = get_missing_values_table(loan_df)\n",
    "missing_values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Columns with under 15% missing values:', \n",
    "      missing_values_df[missing_values_df['Portion_Missing']<=0.15].shape[0])\n",
    "\n",
    "#Plot the distribution of Portions of missing values for the columns\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.distplot(missing_values_df['Portion_Missing'], bins=10, kde=False, rug=True)\n",
    "ax.set_title('Distribution of Portion of Missing Values')\n",
    "ax.set_xlabel('Portion of Missing Values for Columns in Dataset')\n",
    "ax.set_ylabel('Count')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon first glance, we see that there are many columns that do have a reasonably low level of missingess: 93 columns that have less than 15% missing values.\n",
    "\n",
    "There seems to be a small concentration of columns between 60-70% missing values. Below, we explore this and see that there are 11 columns with almost exactly the same number of missing values. Furthermore, using the issue_d column (which indicates the date the date in which the loan was issued), we found that these variables had missing values for all loans issued prior to 2015-12-01. It's possible that the Lending Club simply did not record or use this particular information from potential borrowers until a later date. We have chosen not to include these columns because:\n",
    "\n",
    "there are many other columns that capture similar credit-related information; and\n",
    "\n",
    "we want to keep the older loan information in the dataset, especially since we are looking at only completed loans. Removing the older samples would greatly reduce our sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_grp = missing_values_df[(missing_values_df['Portion_Missing']>=0.6)&(missing_values_df['Portion_Missing']<=0.7)]\n",
    "display(missing_grp)\n",
    "\n",
    "missing_columns = missing_grp.index\n",
    "\n",
    "earliest_date = []\n",
    "for column in missing_columns:\n",
    "    earliest_date.append(min(loan_df[~loan_df[column].isnull()]['issue_d'])) \n",
    "\n",
    "display(pd.DataFrame({'Column':missing_columns,\n",
    "                      'Earliest issue_d for which column value is not null':earliest_date}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: Column Removal and Selection\n",
    "\n",
    "## 1. Identification Columns\n",
    "- **Dropped Columns**: \n",
    "  - `id`, `member_id`, `url`\n",
    "  - **Reason**: These columns contain 100% missing values and are identifiers, which are not relevant to the model.\n",
    "  - `next_pymnt_d`: Also has 100% missing values because these loans are completed and no next payment date exists.\n",
    "\n",
    "\n",
    "\n",
    "## 2. Single-Value Columns\n",
    "- **Dropped Columns**:\n",
    "  - `pymnt_plan`, `out_prncp`, `out_prncp_inv`, `policy_code`\n",
    "  - **Reason**: These columns contain only one unique value, offering no variance or predictive power.\n",
    "\n",
    "\n",
    "\n",
    "## 3. Columns with Large Missingness\n",
    "- **Dropped Columns**:\n",
    "  - `open_acc_6m`, `open_act_il`, `open_il_12m`, `open_il_24m`, `total_bal_il`, `open_rv_12m`, `open_rv_24m`, `max_bal_bc`, `inq_fi`, `total_cu_tl`, `inq_last_12m`\n",
    "  - **Reason**: These columns have a large number of missing values, primarily for loans issued prior to April 2016. Retaining these would greatly reduce the dataset size, so they were excluded. Similar information is captured by other columns.\n",
    "  - `il_util`, `all_util`, `mths_since_rcnt_il`: Slightly more missing data but followed the same trend and were removed for the same reasons.\n",
    "\n",
    "\n",
    "\n",
    "## 4. Hardship-Related Variables\n",
    "- **Dropped Columns**:\n",
    "  - `deferral_term`, `hardship_amount`, `hardship_dpd`, `hardship_end_date`, `hardship_flag`, `hardship_last_payment_amount`, `hardship_length`, `hardship_loan_status`, `hardship_payoff_balance_amount`, `hardship_reason`, `hardship_start_date`, `hardship_status`, `hardship_type`, `orig_projected_additional_accrued_interest`, `payment_plan_start_date`\n",
    "  - **Reason**: These columns pertain to borrowers on hardship plans. Since the information is coded as missing for borrowers not on hardship plans and would not be known at loan origination, they were excluded.\n",
    "\n",
    "\n",
    "\n",
    "## 5. Borrower-Provided Text Fields\n",
    "- **Dropped Columns**:\n",
    "  - `desc`, `title`, `emp_title`\n",
    "  - **Reason**: These are string variables with borrower-provided text. Equivalent categorical variables exist that capture similar information.\n",
    "\n",
    "\n",
    "\n",
    "## 6. Settlement-Related Variables\n",
    "- **Dropped Columns**:\n",
    "  - `debt_settlement_flag`, `debt_settlement_flag_date`, `settlement_amount`, `settlement_date`, `settlement_percentage`, `settlement_status`, `settlement_term`, `recoveries`, `collection_recovery_fee`\n",
    "  - **Reason**: These variables relate to specifics of loan settlement, which would not be known at loan origination and are not helpful for predictive modeling.\n",
    "\n",
    "\n",
    "\n",
    "## 7. Lending Club Loan-Specific Information\n",
    "- **Dropped Columns**:\n",
    "  - `funded_amnt`, `funded_amnt_inv`, `last_pymnt_amnt`, `out_prncp`, `out_prncp_inv`, `total_pymnt`, `total_pymnt_inv`, `total_rec_int`, `total_rec_late_fee`, `total_rec_prncp`, `last_pymnt_d`, `last_credit_pull_d`, `disbursement_method`\n",
    "  - **Reason**: These variables provide information about loan specifics (e.g., late fees, payments made) that would not be known at loan origination.\n",
    "\n",
    "\n",
    "\n",
    "## 8. FICO-Related Columns\n",
    "### Dropped SEC FICO Columns:\n",
    "- **Dropped Columns**:\n",
    "  - `sec_app_fico_range_high`, `sec_app_fico_range_low`\n",
    "  - **Reason**: These columns contain a significant number of missing values.\n",
    "\n",
    "### Dropped Last FICO Columns:\n",
    "- **Dropped Columns**:\n",
    "  - `last_fico_range_high`, `last_fico_range_low`\n",
    "  - **Reason**: Represent the borrower’s most recent FICO score, which might have been updated after the loan was issued. Including these could lead to **data leakage**.\n",
    "\n",
    "### Included High/Low FICO Columns:\n",
    "- **Kept Columns**:\n",
    "  - `fico_range_high`, `fico_range_low`\n",
    "  - **Reason**: Represent the borrower’s FICO score **at loan origination**, which is critical for predicting loan performance. \n",
    "  - **Note**: These columns are perfectly correlated. To avoid redundancy, only `fico_range_high` was retained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['id', 'member_id', 'url', 'next_pymnt_d', 'pymnt_plan', 'out_prncp',\n",
    "           'out_prncp_inv', 'policy_code', 'open_acc_6m', 'open_act_il', 'open_il_12m',\n",
    "           'open_il_24m', 'total_bal_il', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
    "           'inq_fi', 'total_cu_tl', 'inq_last_12m', 'il_util', 'all_util','mths_since_rcnt_il',\n",
    "           'num_tl_120dpd_2m', 'num_tl_30dpd', 'deferral_term', 'hardship_amount',\n",
    "           'hardship_dpd', 'hardship_end_date', 'hardship_flag', 'hardship_last_payment_amount',\n",
    "           'hardship_length', 'hardship_loan_status', 'hardship_payoff_balance_amount',\n",
    "           'hardship_reason', 'hardship_start_date', 'hardship_status', 'hardship_type',\n",
    "           'orig_projected_additional_accrued_interest', 'payment_plan_start_date',\n",
    "           'desc', 'title', 'emp_title', 'debt_settlement_flag', 'debt_settlement_flag_date',\n",
    "           'settlement_amount', 'settlement_date', 'settlement_percentage', 'settlement_status',\n",
    "           'settlement_term', 'recoveries', 'collection_recovery_fee', 'funded_amnt',\n",
    "           'funded_amnt_inv', 'last_pymnt_amnt', 'out_prncp', 'out_prncp_inv',  'total_pymnt',\n",
    "           'total_pymnt_inv', 'total_rec_int', 'total_rec_late_fee', 'total_rec_prncp',\n",
    "           'last_pymnt_d',  'last_credit_pull_d', 'disbursement_method', 'initial_list_status',\n",
    "           'fico_range_low','last_fico_range_high','last_fico_range_low','sec_app_fico_range_high','sec_app_fico_range_low' ]\n",
    "\n",
    "potential_features = np.setdiff1d(loan_df.columns.tolist(), exclude)\n",
    "\n",
    "print(len(potential_features))\n",
    "print(sorted(potential_features))\n",
    "\n",
    "loan_df = loan_df[potential_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize missingness on the remaining columns and see that many of the columns are new from 2012-08-01 and later. We choose to work with data from this date and beyond since the data from prior to this date is only a small subset of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_missingness_by_issue_d(df):\n",
    "    missing_values_df = get_missing_values_table(df)\n",
    "    earliest_date = []\n",
    "    cols_with_missing_vals = missing_values_df[(missing_values_df.Portion_Missing<1) &\n",
    "                                           (missing_values_df.Missing_Count >0)].index\n",
    "\n",
    "    for column in cols_with_missing_vals:\n",
    "        earliest_date.append(min(loan_df[~loan_df[column].isnull()]['issue_d'])) \n",
    "\n",
    "    df = pd.DataFrame({'Column':cols_with_missing_vals,\n",
    "                      'Earliest issue_d for which column value is not null':earliest_date})\n",
    "    \n",
    "    return df.sort_values(by='Earliest issue_d for which column value is not null', ascending=False)\n",
    "\n",
    "view_missingness_by_issue_d(loan_df).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we see that there are columns relating to details of applications that have multiple borrowers (co-borrowers). These columns only have non-null values from issue dates of 2017-03-01 and later (or 2015-10-01 and later for 'dti_joint', 'annual_inc_joint', and 'verification_status_joint'), so we remove these columns. We remove all of these columns:\n",
    "\n",
    "annual_inc_joint, dti_joint, revol_bal_joint, sec_app_chargeoff_within_12_mths, sec_app_collections_12_mths_ex_med, sec_app_earliest_cr_line, sec_app_inq_last_6mths, sec_app_mort_acc, sec_app_mths_since_last_major_derog, sec_app_num_rev_accts, sec_app_open_acc, sec_app_open_act_il, sec_app_revol_util, verification_status_joint]\n",
    "\n",
    "Note that we still do have the application_type variable, which is a simple binary indicator of whether or not the application had co-borrowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coborrower_cols =  ['annual_inc_joint', 'dti_joint', 'revol_bal_joint',\n",
    "                    'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med',\n",
    "                    'sec_app_earliest_cr_line', 'sec_app_inq_last_6mths', 'sec_app_mort_acc',\n",
    "                    'sec_app_mths_since_last_major_derog', 'sec_app_num_rev_accts',\n",
    "                    'sec_app_open_acc', 'sec_app_open_act_il', 'sec_app_revol_util',\n",
    "                    'verification_status_joint']\n",
    "\n",
    "potential_features = np.setdiff1d(loan_df.columns.tolist(), coborrower_cols)\n",
    "loan_df = loan_df[potential_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing these colummns, we take another look at the remaining columns that have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(view_missingness_by_issue_d(loan_df))\n",
    "\n",
    "get_missing_values_table(loan_df).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that many of the columns only have non-null values for issue dates of 2013-04-01 and later, so we remove the samples that have issue_dates prior to this. We see that this only reduces our sample size by a small amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows in dataset: {}\".format (loan_df.shape[0]))\n",
    "\n",
    "loan_df = loan_df[pd.to_datetime(loan_df['issue_d'], format='%b-%Y') >= pd.to_datetime('03/01/2013', format='%m/%d/%Y')]\n",
    "\n",
    "\n",
    "print(\"Number of rows in dataset after removing loans issued prior to 2013-04-01: {}\"\\\n",
    "      .format (loan_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking another look at missingness: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(view_missingness_by_issue_d(loan_df))\n",
    "\n",
    "get_missing_values_table(loan_df).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The missingness for the remaining columns is much more reasonable, but there are still a few columns with large portions of missing values. Consulting the data dictionary reveals a plausible explanation for this:\n",
    "\n",
    "Many of the columns that still have high levels of missingness are those which measure \"months since\" something happened. For example, months_since_recent_bc_dlq measures \"Months since most recent bankcard delinquency.\" Thus, it's likely that the \"missing\" values are not truly missing data; rather, the borrower has simply never had a bankcard delinquency. Thus, we choose to process the \"month since\" columns by filling the null values with the maximum observed value + 1, so that the borrowers who have never had delinquencies just have the largest value for number of months since delinquency. Since we will be using decision-tree based models, this is an appropriate approach that allows the decision tree to separate the borrowers who have had recent delinquencies from those who have not.\n",
    "\n",
    "We also process a few other columns below:\n",
    "\n",
    "Re-categorize emp_length so that there are fewer categories\n",
    "Cast revol_util to float\n",
    "Change loan_grade and grade values to numerical rankings (i.e., an ordinal variable with the lowest grade/subgrade indicating the least-risky loans)\n",
    "credit_line_age and earliest_cr_line\n",
    "int_rate\n",
    "zip_code\n",
    "fully_paid and loan_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('emp_length value counts: \\n{}\\n'.format(loan_df.emp_length.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emp_length(df):\n",
    "    df_new = df.copy()\n",
    "    #0-1 years inclues: null, None, < 1 year, 1 year\n",
    "    df_new['emp_length'] = df_new['emp_length'].fillna('0-1 years')\n",
    "    df_new['emp_length'] = np.where(df_new['emp_length'].isin([np.nan,None,'< 1 year','1 year']),\n",
    "                                     '0-1 years',df_new['emp_length'])\n",
    "    #2-4 years inclues: 2 years, 3 years, 4 years\n",
    "    df_new['emp_length'] = np.where(df_new['emp_length'].isin(['2 years','3 years','4 years']),\n",
    "                                     '2-4 years',df_new['emp_length'])\n",
    "    \n",
    "    #5-9 years inclues: 5 years, 6 years, 7 years, 8 years, 9 years\n",
    "    df_new['emp_length'] = np.where(df_new['emp_length'].isin(['5 years','6 years','7 years','8 years','9 years']),\n",
    "                                     '5-9 years',df_new['emp_length'])\n",
    "    #10+ years includes 10+ years (no change)\n",
    "    return df_new\n",
    "\n",
    "def process_revol_util(df):\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    df_new['revol_util'] = df_new['revol_util'].fillna(-100)\n",
    "    df_new['revol_util'] = df_new['revol_util'].apply(lambda x: float(str(x).split('%')[0])/100)\n",
    "    df_new['revol_util'] = np.where(df_new['revol_util']==-1.0,np.nan,df_new['revol_util'])\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "def process_month_since_cols(df):\n",
    "    df_new = df.copy()\n",
    "\n",
    "    mo_since_cols = ['mo_sin_old_il_acct','mths_since_last_delinq','mths_since_last_major_derog',\n",
    "                     'mths_since_last_record','mths_since_recent_bc_dlq','mths_since_recent_inq',\n",
    "                     'mths_since_recent_revol_delinq','mo_sin_old_rev_tl_op','mths_since_recent_bc',\n",
    "                     'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl']\n",
    "\n",
    "    for col in mo_since_cols:\n",
    "        df_new[col].fillna(df_new[col].max()+1, inplace=True)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "def process_loan_grades(df):\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # turn sub_grade into ordinal mapping\n",
    "    sorted_subgrades = sorted(df.sub_grade.unique())\n",
    "    subgrade_dict = dict(zip(sorted_subgrades, range(len(sorted_subgrades))))\n",
    "    df_new['sub_grade'] = df_new['sub_grade'].map(subgrade_dict)\n",
    "    \n",
    "    # turn grade into ordinal mapping\n",
    "    sorted_grades = sorted(df.grade.unique())\n",
    "    grade_dict = dict(zip(sorted_grades, range(len(sorted_grades))))\n",
    "    df_new['grade'] = df_new['grade'].map(grade_dict)\n",
    "    return df_new\n",
    "    \n",
    "    \n",
    "def process_loan_cols(df):\n",
    "    df_processed = process_emp_length(df)\n",
    "    df_processed = process_revol_util(df_processed)\n",
    "    df_processed = process_month_since_cols(df_processed)\n",
    "    df_processed = process_loan_grades(df_processed)\n",
    "    \n",
    "    #add credit_line_age\n",
    "    df_processed['issue_d'] = pd.to_datetime(df_processed['issue_d'], format='%b-%Y')\n",
    "    df_processed['earliest_cr_line'] = pd.to_datetime(df_processed['earliest_cr_line'])\n",
    "    df_processed['credit_line_age'] = df_processed['issue_d'] - pd.to_datetime(df_processed['earliest_cr_line'])\n",
    "    df_processed = df_processed.drop(columns='earliest_cr_line')\n",
    "\n",
    "    #process int_rate, zip_code, credit_line_age\n",
    "    df_processed['int_rate'] = df_processed['int_rate'].apply(lambda x: float(str(x).split('%')[0])/100)\n",
    "    df_processed['zip_code'] = df_processed['zip_code'].apply(lambda x: x[:3])\n",
    "    df_processed['credit_line_age'] = df_processed['credit_line_age'].apply(lambda x: x.days)\n",
    "    \n",
    "    # generate new column for outcome variable ('fully_paid'); drop 'loan_status'\n",
    "    df_processed['fully_paid'] = df_processed['loan_status'].map({'Fully Paid':1, 'Charged Off':0})\n",
    "    df_processed = df_processed.drop(columns='loan_status')\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "loan_df = process_loan_cols(loan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values: Imputation for Continuous Columns\n",
    "We will fill the remaining columns' missing values using linear regression model-based imputation. First, we verify that all of the remaining columns are continuous float-64 variables for which this model imputation is appropriate.\n",
    "\n",
    "Then, we use pd.get_dummies() to get dummy-variables for the necessary categorical columns. This is an important step which should be done prior to model-based imputation\n",
    "\n",
    "Finally, we proceed with our imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = get_missing_values_table(loan_df)\n",
    "display(missing_data[missing_data.Missing_Count!=0])\n",
    "missing_cols = missing_data[missing_data.Missing_Count!=0].index\n",
    "\n",
    "print(\"datatypes of the columns that still have missing values: \")\n",
    "print(loan_df[missing_cols].dtypes.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before performing imputation, we need to process some of the categorical variables using pd.get_dummies. We do so below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rerun Types\n",
    "types_df = pd.DataFrame(loan_df.dtypes,columns=['Types'])\n",
    "display(types_df[types_df['Types']!='float64'].sort_values(by='Types'))\n",
    "\n",
    "\n",
    "object_vars=loan_df.select_dtypes(include='object').columns.tolist()\n",
    "object_vars = np.setdiff1d(object_vars,['addr_state', 'zip_code'])\n",
    "print(object_vars)\n",
    "\n",
    "#Dummy encoding\n",
    "loan_df = pd.get_dummies(loan_df,columns=object_vars,drop_first=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns where imputation is neededpd.\n",
    "missing_cols = loan_df.columns[loan_df.isnull().any()].tolist()\n",
    "\n",
    "#verify they're all continuous dtypes appropriate for linear regression imputation\n",
    "loan_df[missing_cols].dtypes.unique() # all float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performming Linear Regression Model-Based Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_continuous(df, missing_columns, cols_to_exclude):\n",
    "    clean_df = df.copy()\n",
    "    \n",
    "    for column in missing_columns:\n",
    "        types_df = pd.DataFrame(df.dtypes, columns=['Types'])\n",
    "        \n",
    "        # Remove response variable\n",
    "        impute_train = clean_df[~clean_df[column].isnull()].drop(columns=cols_to_exclude).sample(frac=0.1, random_state=12)\n",
    "        \n",
    "        # Split target\n",
    "        X_impute_train = impute_train.drop(columns=column)\n",
    "        Y_impute_train = impute_train[column]\n",
    "        \n",
    "        # Mean Imputation for current nulls for columns that did not get imputed yet\n",
    "        X_impute_train = X_impute_train.fillna(X_impute_train.mean())\n",
    "        \n",
    "        # Train LinearRegression\n",
    "        impute_ols = LinearRegression(fit_intercept=True)\n",
    "        impute_ols.fit(X_impute_train, Y_impute_train)\n",
    "        \n",
    "        # Generate new temp column with model predictions\n",
    "        # Only replace rows where the value is null with the predicted value\n",
    "        exclude_cols = cols_to_exclude + [column]\n",
    "        predictions = clean_df.drop(columns=exclude_cols)\n",
    "        \n",
    "        # Mean Imputation for current nulls for columns that did not get imputed yet\n",
    "        predictions = predictions.fillna(predictions.mean())\n",
    "        clean_df['temp'] = impute_ols.predict(predictions)\n",
    "        \n",
    "        clean_df[column] = np.where(clean_df[column].isnull(), \n",
    "                                  clean_df['temp'], \n",
    "                                  clean_df[column])\n",
    "        clean_df = clean_df.drop(columns='temp')\n",
    "    \n",
    "    return clean_df\n",
    "\n",
    "# Call the function\n",
    "clean_df = impute_missing_continuous(\n",
    "    loan_df, \n",
    "    missing_columns=missing_cols, \n",
    "    cols_to_exclude=['fully_paid', 'issue_d', 'zip_code', 'addr_state']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"float64 columns: \")\n",
    "print(clean_df.dtypes[clean_df.dtypes=='float64'].index.tolist())\n",
    "\n",
    "print(\"\\nnon-float64 columns: \")\n",
    "print(clean_df.dtypes[clean_df.dtypes!='float64'])\n",
    "\n",
    "print(\"\\n\\nVisualizing unique values for non-float64 variables (except for zip_code and issue_d)\")\n",
    "for col in clean_df.dtypes[clean_df.dtypes!='float64'].index.tolist():\n",
    "    if not col in['issue_d', 'zip_code']:\n",
    "        print(\"\\n\", col)\n",
    "        print(clean_df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_pickle('clean_df_5pct_subset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Clean on Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('accepted_2007_to_2018Q3.csv.gz')\n",
    "loan_df = df[df['loan_status'].isin(['Charged Off', 'Fully Paid'])]\n",
    "\n",
    "exclude = ['id', 'member_id', 'url', 'next_pymnt_d', 'pymnt_plan', 'out_prncp',\n",
    "           'out_prncp_inv', 'policy_code', 'open_acc_6m', 'open_act_il', 'open_il_12m',\n",
    "           'open_il_24m', 'total_bal_il', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
    "           'inq_fi', 'total_cu_tl', 'inq_last_12m', 'il_util', 'all_util','mths_since_rcnt_il',\n",
    "           'num_tl_120dpd_2m', 'num_tl_30dpd', 'deferral_term', 'hardship_amount',\n",
    "           'hardship_dpd', 'hardship_end_date', 'hardship_flag', 'hardship_last_payment_amount',\n",
    "           'hardship_length', 'hardship_loan_status', 'hardship_payoff_balance_amount',\n",
    "           'hardship_reason', 'hardship_start_date', 'hardship_status', 'hardship_type',\n",
    "           'orig_projected_additional_accrued_interest', 'payment_plan_start_date',\n",
    "           'desc', 'title', 'emp_title', 'debt_settlement_flag', 'debt_settlement_flag_date',\n",
    "           'settlement_amount', 'settlement_date', 'settlement_percentage', 'settlement_status',\n",
    "           'settlement_term', 'recoveries', 'collection_recovery_fee', 'funded_amnt',\n",
    "           'funded_amnt_inv', 'last_pymnt_amnt', 'out_prncp', 'out_prncp_inv',  'total_pymnt',\n",
    "           'total_pymnt_inv', 'total_rec_int', 'total_rec_late_fee', 'total_rec_prncp',\n",
    "           'last_pymnt_d',  'last_credit_pull_d', 'disbursement_method', 'initial_list_status',\n",
    "           'annual_inc_joint', 'dti_joint', 'revol_bal_joint','sec_app_chargeoff_within_12_mths',\n",
    "           'sec_app_collections_12_mths_ex_med','sec_app_earliest_cr_line', 'sec_app_inq_last_6mths',\n",
    "           'sec_app_mort_acc','sec_app_mths_since_last_major_derog', 'sec_app_num_rev_accts',\n",
    "           'sec_app_open_acc', 'sec_app_open_act_il', 'sec_app_revol_util',\n",
    "           'verification_status_joint',\n",
    "           'fico_range_high','fico_range_low','last_fico_range_high','last_fico_range_low','sec_app_fico_range_high','sec_app_fico_range_low']\n",
    "\n",
    "potential_features = np.setdiff1d(loan_df.columns.tolist(), exclude)\n",
    "loan_df = loan_df[potential_features]\n",
    "\n",
    "loan_df = loan_df[pd.to_datetime(loan_df['issue_d'], format='%b-%Y') >= pd.to_datetime('03/01/2013', format='%m/%d/%Y')]\n",
    "\n",
    "loan_df = process_loan_cols(loan_df)\n",
    "\n",
    "object_vars = loan_df.select_dtypes(include='object').columns.tolist()\n",
    "vars_for_dummies = np.setdiff1d(object_vars,['addr_state', 'zip_code'])\n",
    "\n",
    "tmp_df = loan_df[vars_for_dummies]\n",
    "loan_df = pd.get_dummies(loan_df,columns=vars_for_dummies,drop_first=True) \n",
    "\n",
    "missing_cols = loan_df.columns[loan_df.isnull().any()].tolist()\n",
    "\n",
    "clean_df = impute_missing_continuous(loan_df, missing_columns=missing_cols,\n",
    "                                     cols_to_exclude=['fully_paid','issue_d', 'zip_code', 'addr_state'])\n",
    "\n",
    "for col in vars_for_dummies:\n",
    "    clean_df[col] = tmp_df[col]\n",
    "    \n",
    "print(sorted(clean_df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_pickle('clean_df_for_eda.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.groupby(['fully_paid']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorten_df = pd.read_pickle('clean_df_for_eda.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset while maintaining distribution.\n",
    "\n",
    "subset_size = 200000\n",
    "\n",
    "proportions = shorten_df['fully_paid'].value_counts(normalize=True)\n",
    "sample_sizes = (proportions * subset_size).round().astype(int)\n",
    "\n",
    "shorten_df = (\n",
    "    shorten_df.groupby('fully_paid', group_keys=False)\n",
    "    .apply(lambda group: group.sample(n=sample_sizes[group.name], random_state=42))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapOutliers(df,columns_to_cap):\n",
    "    for column in columns_to_cap:\n",
    "        Q1 = df[column].quantile(.25)\n",
    "        Q3 = df[column].quantile(.75)\n",
    "        IQR = Q3 - Q1\n",
    "        upper = (Q3 + 1.5 * IQR)\n",
    "        lower = (Q1 - 1.5 * IQR)\n",
    "\n",
    "        df[column] = np.where(df[column] > upper,upper,np.where(df[column] < lower,lower,df[column]))\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_cap = ['acc_now_delinq', 'acc_open_past_24mths', 'annual_inc', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'collections_12_mths_ex_med', 'delinq_2yrs', 'delinq_amnt', 'dti', 'inq_last_6mths', 'installment', 'int_rate', 'loan_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_last_delinq', 'mths_since_last_major_derog', 'mths_since_last_record', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'open_acc', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec', 'pub_rec_bankruptcies', 'revol_bal', 'revol_util', 'tax_liens', 'tot_coll_amt', 'tot_cur_bal', 'tot_hi_cred_lim', 'total_acc', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'total_rev_hi_lim']\n",
    "\n",
    "loan_df = CapOutliers(shorten_df,columns_to_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(loan_df,columns=['application_type','emp_length','home_ownership','purpose','term','verification_status','addr_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(['fully_paid','zip_code','issue_d','int_rate','installment','grade','sub_grade'],axis=1)\n",
    "y = df_encoded['fully_paid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train an initial XGBoost model\n",
    "initial_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "initial_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Perform feature selection\n",
    "selection = SelectFromModel(initial_model, prefit=True, threshold='mean')\n",
    "X_train_selected = selection.transform(X_train_scaled)\n",
    "X_test_selected = selection.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define a parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'eval_metric': ['logloss'],\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'max_depth': [3, 5],\n",
    "    'min_child_weight': [1, 3],\n",
    "    'subsample': [0.5, 0.9],\n",
    "    'colsample_bytree': [0.5, 0.8],\n",
    "    'scale_pos_weight': [1, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform hyperparameter tuning\n",
    "model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1', \n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_selected)\n",
    "y_pred_proba = best_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "xgboost_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'precision': precision_score(y_test, y_pred),\n",
    "    'recall': recall_score(y_test, y_pred),\n",
    "    'f1': f1_score(y_test, y_pred),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "    'best_params': grid_search.best_params_\n",
    "}\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "for metric, value in xgboost_metrics.items():\n",
    "    print(f\"{metric.capitalize()}: {value:.4f}\" if isinstance(value, float) else f\"{metric.capitalize()}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Visualize feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "xgb.plot_importance(best_model, importance_type='weight', max_num_features=20)\n",
    "plt.title(\"Feature Importance from XGBoost\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "# Convert selected features back to their original names\n",
    "selected_features = X.columns[selection.get_support()]\n",
    "\n",
    "# Determine the number of rows and columns based on the number of features\n",
    "num_features = len(selected_features)\n",
    "num_cols = 2  # You can adjust the number of columns as desired\n",
    "num_rows = ceil(num_features / num_cols)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over all selected features\n",
    "for i, feature in enumerate(selected_features):\n",
    "    PartialDependenceDisplay.from_estimator(\n",
    "        best_model, X_test_selected, features=[i], feature_names=selected_features, ax=axes[i]\n",
    "    )\n",
    "\n",
    "# Hide any unused subplots if there are more subplots than features\n",
    "for j in range(num_features, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tools import display_dataframe_to_user\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Standardize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define Hyperparameter Grid\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Regularization strength\n",
    "    'penalty': ['l2'],        # L2 regularization\n",
    "    'solver': ['lbfgs']       # Optimization solver\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Hyperparameter Tuning with GridSearchCV\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=lr_params,\n",
    "    scoring='f1',  # Optimize for F1-score\n",
    "    cv=3,          # 3-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1      # Use all available CPU cores\n",
    ")\n",
    "grid_search_lr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Get the Best Model and Parameters\n",
    "best_log_reg = grid_search_lr.best_estimator_\n",
    "best_params = grid_search_lr.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Make Predictions\n",
    "y_pred = best_log_reg.predict(X_test_scaled)\n",
    "y_pred_proba = best_log_reg.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Compute Evaluation Metrics\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Create the dictionary\n",
    "logistic_metrics = {\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision (Class 1)\": precision,\n",
    "    \"Recall (Class 1)\": recall,\n",
    "    \"F1-Score (Class 1)\": f1,\n",
    "    \"AUC (ROC)\": roc_auc\n",
    "}\n",
    "\n",
    "print(\"\\nLogistic Regression Metrics After Hyperparameter Tuning:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Generate Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Plot ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Feature Importance (Coefficient Magnitudes)\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": abs(best_log_reg.coef_[0])\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features by Importance:\")\n",
    "print(feature_importances.head(10))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importances[\"Feature\"].head(10), feature_importances[\"Importance\"].head(10))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 10 Features by Importance\")\n",
    "plt.xlabel(\"Coefficient Magnitude\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Partial Dependence Plots for Top Features\n",
    "# Selecting top features\n",
    "top_features = feature_importances[\"Feature\"].head(3).values\n",
    "\n",
    "fig, axes = plt.subplots(len(top_features), 1, figsize=(10, 10))\n",
    "for i, feature in enumerate(top_features):\n",
    "    PartialDependenceDisplay.from_estimator(\n",
    "        best_log_reg, X_test_scaled, features=[i], feature_names=X.columns, ax=axes[i]\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame([\n",
    "    {\"Metric\": \"Accuracy\", \"Logistic Regression\": logistic_metrics[\"Accuracy\"], \"XGBoost\": xgboost_metrics[\"Accuracy\"]},\n",
    "    {\"Metric\": \"AUC (ROC)\", \"Logistic Regression\": logistic_metrics[\"AUC (ROC)\"], \"XGBoost\": xgboost_metrics[\"AUC (ROC)\"]},\n",
    "    {\"Metric\": \"Precision (Class 1)\", \"Logistic Regression\": logistic_metrics[\"Precision (Class 1)\"], \"XGBoost\": xgboost_metrics[\"Precision (Class 1)\"]},\n",
    "    {\"Metric\": \"Recall (Class 1)\", \"Logistic Regression\": logistic_metrics[\"Recall (Class 1)\"], \"XGBoost\": xgboost_metrics[\"Recall (Class 1)\"]},\n",
    "    {\"Metric\": \"F1-Score (Class 1)\", \"Logistic Regression\": logistic_metrics[\"F1-Score (Class 1)\"], \"XGBoost\": xgboost_metrics[\"F1-Score (Class 1)\"]}\n",
    "])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Performance Summary: Logistic Regression vs. XGBoost\")\n",
    "print(comparison)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
